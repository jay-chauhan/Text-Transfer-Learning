p <- p + labs(title = "Bootstrap distribution of the estimated re
gression parameter of Temperature")
print(p)
dat.bs.HumidityRatio <- data.frame(bs.HumidityRatio.sorted)
p <- ggplot(dat.bs.HumidityRatio, aes(x = bs.HumidityRatio))
p <- p + geom_histogram(aes(y=..density..))
p <- p + geom_density(alpha=0.1, fill="white")
p <- p + geom_rug()
# vertical line at CI
p <- p + geom_vline(xintercept=CI.bs[1], colour="blue", linetype=
"longdash")
p <- p + geom_vline(xintercept=CI.bs[2], colour="blue", linetype=
"longdash")
p <- p + labs(title = "Bootstrap distribution of the estimated re
gression parameter of Humidity Ratio")
print(p)
bs.HumidityRatio<-bs_glm.demo[,6]
bs.HumidityRatio.sorted<-sort(bs.HumidityRatio)
CI.bs <- c(bs.HumidityRatio.sorted[round(0.025*R)],bs.HumidityRatio.sorted[round(0.975*R+1)])
CI.bs
dat.bs.HumidityRatio <- data.frame(bs.HumidityRatio.sorted)
p <- ggplot(dat.bs.HumidityRatio, aes(x = bs.HumidityRatio))
p <- p + geom_histogram(aes(y=..density..))
p <- p + geom_density(alpha=0.1, fill="white")
p <- p + geom_rug()
# vertical line at CI
p <- p + geom_vline(xintercept=CI.bs[1], colour="blue", linetype=
"longdash")
p <- p + geom_vline(xintercept=CI.bs[2], colour="blue", linetype=
"longdash")
p <- p + labs(title = "Bootstrap distribution of the estimated re
gression parameter of Humidity Ratio")
print(p)
occp<-read.csv("/Users/jaychauhan/Documents/498/Assignment3/occupancy_data/datatraining.txt")
demo<-occp[,2:7]
occp$Occupancy <- as.factor(occp$Occupancy)
demo[1:5,]
glm.demo<-glm(Occupancy~., data=demo, family = "binomial")
summary(glm.demo)
R<-10000
bs_glm.demo<-matrix(NA,nrow=R,ncol=length(glm.demo$coefficients))
for(i in 1:R){
resam_ID<-sample(x=c(1:dim(demo)[1]),size=floor(dim(demo)[1]),replace=TRUE)
resam_data<-demo[resam_ID,]
bs_glm<-glm(Occupancy~., data=resam_data, family = "binomial")
bs_glm.demo[i,] <- bs_glm$coefficients
}
R<-100
bs_glm.demo<-matrix(NA,nrow=R,ncol=length(glm.demo$coefficients))
for(i in 1:R){
resam_ID<-sample(x=c(1:dim(demo)[1]),size=floor(dim(demo)[1]*60),replace=FALSE)
resam_data<-demo[resam_ID,]
bs_glm<-glm(Occupancy~., data=resam_data, family = "binomial")
bs_glm.demo[i,] <- bs_glm$coefficients
}
R<-100
bs_glm.demo<-matrix(NA,nrow=R,ncol=length(glm.demo$coefficients))
for(i in 1:R){
resam_ID<-sample(x=c(1:dim(demo)[1]),size=floor(dim(demo)[1]*0.6),replace=FALSE)
resam_data<-demo[resam_ID,]
bs_glm<-glm(Occupancy~., data=resam_data, family = "binomial")
bs_glm.demo[i,] <- bs_glm$coefficients
}
R<-10000
bs_glm.demo<-matrix(NA,nrow=R,ncol=length(glm.demo$coefficients))
for(i in 1:R){
resam_ID<-sample(x=c(1:dim(demo)[1]),size=floor(dim(demo)[1]*0.6),replace=FALSE)
resam_data<-demo[resam_ID,]
bs_glm<-glm(Occupancy~., data=resam_data, family = "binomial")
bs_glm.demo[i,] <- bs_glm$coefficients
}
R<-10000
bs_glm.demo<-matrix(NA,nrow=R,ncol=length(glm.demo$coefficients))
for(i in 1:R){
resam_ID<-sample(x=c(1:dim(demo)[1]),size=floor(dim(demo)[1]*0.7),replace=FALSE)
resam_data<-demo[resam_ID,]
bs_glm<-glm(Occupancy~., data=resam_data, family = "binomial")
bs_glm.demo[i,] <- bs_glm$coefficients
}
R<-10000
bs_glm.demo<-matrix(NA,nrow=R,ncol=length(glm.demo$coefficients))
for(i in 1:R){
resam_ID<-sample(x=c(1:dim(demo)[1]),size=floor(dim(demo)[1]*0.6),replace=FALSE)
resam_data<-demo[resam_ID,]
bs_glm<-glm(Occupancy~., data=resam_data, family = "binomial")
bs_glm.demo[i,] <- bs_glm$coefficients
}
occp<-read.csv("/Users/jaychauhan/Documents/498/Assignment3/occupancy_data/datatraining.txt")
demo<-occp[,2:7]
occp$Occupancy <- as.factor(occp$Occupancy)
demo[1:5,]
occp<-read.csv("/Users/jaychauhan/Documents/498/Assignment3/occupancy_data/datatraining.txt")
demo<-occp[,2:7]
occp$Occupancy <- as.factor(occp$Occupancy)
demo[1:4,]
occp<-read.csv("/Users/jaychauhan/Documents/498/Assignment3/occupancy_data/datatraining.txt")
demo<-occp[,2:6]
occp$Occupancy <- as.factor(occp$Occupancy)
demo[1:5,]
occp<-read.csv("/Users/jaychauhan/Documents/498/Assignment3/occupancy_data/datatraining.txt")
demo<-occp[,2:5,7]
occp$Occupancy <- as.factor(occp$Occupancy)
demo[1:5,]
glm.demo<-glm(Occupancy~., data=demo, family = "binomial")
occp<-read.csv("/Users/jaychauhan/Documents/498/Assignment3/occupancy_data/datatraining.txt")
demo<-occp[,c(2:5,7)]
occp$Occupancy <- as.factor(occp$Occupancy)
demo[1:5,]
glm.demo<-glm(Occupancy~., data=demo, family = "binomial")
summary(glm.demo)
R<-10000
bs_glm.demo<-matrix(NA,nrow=R,ncol=length(glm.demo$coefficients))
for(i in 1:R){
resam_ID<-sample(x=c(1:dim(demo)[1]),size=floor(dim(demo)[1]*0.6),replace=FALSE)
resam_data<-demo[resam_ID,]
bs_glm<-glm(Occupancy~., data=resam_data, family = "binomial")
bs_glm.demo[i,] <- bs_glm$coefficients
}
occp<-read.csv("/Users/jaychauhan/Documents/498/Assignment3/occupancy_data/datatraining.txt")
demo<-occp[,2:7]
occp$Occupancy <- as.factor(occp$Occupancy)
demo[1:5,]
glm.demo<-glm(Occupancy~., data=demo, family = "binomial")
summary(glm.demo)
R<-10000
bs_glm.demo<-matrix(NA,nrow=R,ncol=length(glm.demo$coefficients))
for(i in 1:R){
resam_ID<-sample(x=c(1:dim(demo)[1]),size=floor(dim(demo)[1]*0.6),replace=FALSE)
resam_data<-demo[resam_ID,]
bs_glm<-glm(Occupancy~., data=resam_data, family = "binomial")
bs_glm.demo[i,] <- bs_glm$coefficients
}
occp<-read.csv("/Users/jaychauhan/Documents/498/Assignment3/occupancy_data/datatraining.txt")
demo<-occp[,2:7]
occp$Occupancy <- as.factor(occp$Occupancy)
demo[1:5,]
glm.demo<-glm(Occupancy~., data=demo, family = "binomial")
summary(glm.demo)
R<-10000
bs_glm.demo<-matrix(NA,nrow=R,ncol=length(glm.demo$coefficients))
for(i in 1:R){
resam_ID<-sample(x=c(1:dim(demo)[1]),size=floor(dim(demo)[1]*0.6),replace=FALSE)
resam_data<-demo[resam_ID,]
bs_glm<-glm(Occupancy~., data=resam_data, family = "binomial")
bs_glm.demo[i,] <- bs_glm$coefficients
}
R<-10000
bs_glm.demo<-matrix(NA,nrow=R,ncol=length(glm.demo$coefficients))
for(i in 1:R){
resam_ID<-sample(x=c(1:dim(demo)[1]),size=floor(dim(demo)[1]*0.6),replace=FALSE)
resam_data<-demo[resam_ID,]
bs_glm<-glm(Occupancy~., data=resam_data, family = "binomial")
bs_glm.demo[i,] <- bs_glm$coefficients
}
(0.94*-0.15)
(0.94*-0.15)+(0.14*-0.72)+(1.36*-0.64)+(-0.24*0.61)+(0.45*1.11)
(-0.48*0.46)+(0.54*0.37)+(0.91*0.27)+(1.25*1.59)+(-0.11*-.34)
(-0.48*0.46)+(0.54*0.37)+(0.91*0.27)+(1.25*1.59)+(-0.11*0.34)
X1<-c(-0.15,-0.72,1.36,0.61,-1.11)
X2<-c(-0.48,-0.54,-0.91,1.59,0.34)
Y<-c(0.46,-0.37,-0.27,1.35,-0.11)
df<-data.frame(X1,X2,Y)
require(glmnet)
df[:,1:2]
df<-data.frame(X1,X2,Y)
require(glmnet)
df[:,1:2]
df[1,2]
df[1:,2]
df[,1]
fit = glmnet(c(X1,X2),Y ,nlambda = 1)
c(X1,X2)
fit = glmnet(df[,c(1,2)],Y ,nlambda = 1)
df[,c(1,2)]
Y
fit = glmnet(df[,c(1,2)],Y ,nlambda = 1.0)
fit = glmnet(df[,c(1,2)],Y ,nlambda = 1.0)
fit = glmnet(df[,c(1,2)],Y ,nlambda = 1)
df[,c(1,2)]
Y
fit = glmnet(df[,c(1,2)],df$Y ,nlambda = 1)
df$Y
fit = glmnet(df[,c(1,2)],df$Y ,nlambda = 100)
df[,c(1,2)]
df$Y
df<-matrix(data=c(-0.15,-0.72,1.36,0.61,-1.11,-0.48,-0.54,-0.91,1.59,0.34,0.46,-0.37,-0.27,1.35,-0.11),nrow = 5,ncol = 3,dimnames = c('X1','X2','Y'))
c('X1','X2','Y')
df<-matrix(c(-0.15,-0.72,1.36,0.61,-1.11,-0.48,-0.54,-0.91,1.59,0.34,0.46,-0.37,-0.27,1.35,-0.11),nrow = 5,ncol = 3,dimnames = c('X1','X2','Y'))
df<-matrix(c(-0.15,-0.72,1.36,0.61,-1.11,-0.48,-0.54,-0.91,1.59,0.34,0.46,-0.37,-0.27,1.35,-0.11),nrow = 5,ncol = 3)
df
df[1:2]
df[,1:2]
fit = glmnet(df[,1:2],df[,3] ,nlambda = 1)
print(fit)
fit$beta
linear.train <- data.frame(x,y)
x = matrix(c(5,5,2,2,1,0,0,1,-1,1,-1,0,1,-1), nrow = 7, ncol = 2)
y = c(1,1,1,1,-1,-1,-1)
linear.train <- data.frame(x,y)
require( 'ggplot2' )
p <- qplot( data=linear.train, X1, X2, colour=factor(y))
p <- p + labs(title = "Scatterplot of data points of two classes")
print(p)
require( 'kernlab' )
linear.svm <- ksvm(y ~ ., data=linear.train, type='C-svc', kernel='vanilladot', C=10, scaled = FALSE)
alpha(linear.svm)
b(linear.svm)
x = matrix(c(-1,-1,1,1,-1,1,-1,1), nrow = 4, ncol = 2)
y = c(-1,1,1,-1)
linear.train <- data.frame(x,y)
require( 'ggplot2' )
p <- qplot( data=linear.train, X1, X2, colour=factor(y),xlim = c(-1.5,1.5), ylim = c(-1.5,1.5))
p <- p + labs(title = "Scatterplot of data points of two classes")
print(p)
x = matrix(c(-1,-1,1,1,-1,1,-1,1), nrow = 4, ncol = 2)
y = c(-1,1,1,-1)
linear.train <- data.frame(x,y)
require( 'kernlab' )
linear.svm <- ksvm(y ~ ., data=linear.train, type='C-svc', kernel='polydot', kpar=list(degree = 2, offset = 1),  C = 10, scaled = FALSE)
alpha(linear.svm)
b(linear.svm)
(0.94*-0.15)+(0.17*-0.72)+(1.36*0.64)+(-0.24*0.61)+(0.45*1.11)
X1*0.4601
X1<-c(-0.15,-0.72,1.36,0.61,-1.11)
X1*0.4601
(-0.48*0.529)+(-0.54*-0.03)+(0.91*0.895)+(1.069*1.59)+(0.4*0.34)
df<-matrix(c(-0.15,-0.72,1.36,0.61,-1.11,-0.48,-0.54,-0.91,1.59,0.34,0.46,-0.37,-0.27,1.35,-0.11),nrow = 5,ncol = 3)
require(glmnet)
fit = glmnet(df[,1:2],df[,3] ,nlambda = 1)
fit$beta
df
df<-matrix(c(-0.15,-0.72,1.36,0.61,-1.11,-0.48,-0.54,-0.91,1.59,0.34,0.46,-0.37,-0.27,1.35,-0.11),nrow = 5,ncol = 3)
require(glmnet)
df
fit = glmnet(df[,1:2],df[,3] ,nlambda = 1)
fit$beta
library(data.table)
library(ggplot2)
library(tm)
library(SnowballC)
# read in data
dat_bio <- read.csv('biology.csv', stringsAsFactors = F)
dat_cook <- read.csv('cooking.csv', stringsAsFactors = F)
dat_crypt <- read.csv('crypto.csv', stringsAsFactors = F)
dat_diy <- read.csv('diy.csv', stringsAsFactors = F)
dat_robot <- read.csv('robotics.csv', stringsAsFactors = F)
dat_travel <- read.csv('travel.csv', stringsAsFactors = F)
# attach a category label
dat_bio$category <- 'biology'
dat_cook$category <- 'cooking'
dat_crypt$category <- 'crypto'
dat_diy$category <- 'diy'
dat_robot$category <- 'robotics'
dat_travel$category <- 'travel'
# combine and remove from environment
dat_all <- rbind(dat_bio, dat_cook, dat_crypt, dat_diy, dat_robot, dat_travel)
rm(dat_bio, dat_cook, dat_crypt, dat_diy, dat_robot, dat_travel)
# duplicate id values across categories, concat id to category and we're good
print(sum(duplicated(dat_all$id)))  # 27,441
library(dplyr)
unique(dat_all$category)
#
summary(dat_all)
#Merging title and content and creating a corpus
dat_all$title_content =  paste(dat_all$title, dat_all$content, sep=" ")
# removes all html tags
remove_html_tags <- function(htmlString) {
return(gsub("<.*?>", "", htmlString))
}
title_content_pre=remove_html_tags(dat_all$title_content)
title_content_corpus = Corpus(VectorSource(title_content_pre))
title_content_corpus <- tm_map(title_content_corpus, content_transformer(tolower))
title_content_corpus <- tm_map(title_content_corpus, removeNumbers)
title_content_corpus <- tm_map(title_content_corpus, removePunctuation)
title_content_corpus <- tm_map(title_content_corpus, removeWords, c("the", "and", stopwords("english")))
title_content_corpus <-  tm_map(title_content_corpus, stripWhitespace)
title_content_corpus<- tm_map(title_content_corpus, stemDocument, "english")
head(title_content_corpus$content)
title_content_dtm <- DocumentTermMatrix(title_content_corpus)
title_content_dtm
title_content_dtm_tfidf <- DocumentTermMatrix(title_content_corpus, control = list(weighting = weightTfIdf))
title_content_dtm_tfidf = removeSparseTerms(title_content_dtm_tfidf, 0.99)
title_content_dtm_tfidf
# The first document
inspect(title_content_dtm_tfidf[1,])
freq = data.frame(sort(colSums(as.matrix(title_content_dtm_tfidf)), decreasing=TRUE))
wordcloud(rownames(freq), freq[,1], max.words=100, colors=brewer.pal(1, "Dark2"))
dat_all_new = cbind(dat_all$tags, dat_all$category, as.matrix(title_content_dtm_tfidf))
dat_all_new = data.frame(dat_all_new)
tag_corpus = Corpus(VectorSource(dat_all$tags))
tag_corpus = tm_map(tag_corpus, content_transformer(tolower))
tag_corpus = tm_map(tag_corpus, stripWhitespace)
tag_corpus = tm_map(tag_corpus, removeNumbers)
tag_corpus = tm_map(tag_corpus, removePunctuation)
library(qdapTools)
#extract tags from the corpus in df format
tags<-tag_corpus$content
#convert tags into one-hot encoding
tags_ohe<-cbind(tags, mtabulate(strsplit(tags, " ")))
dim(tags_ohe)
#column bind the featureset and outputs to create final dataset
dat_all_new<-cbind(dat_all_new,tags_ohe)
dat_all_test<-tail(dat_all_new,15000)
dat_all_train<-dat_all_new[1:(nrow(dat_all_new)-15000),]
dim(dat_all_train)
dat_all_train <- dat_all_train[ -c(1, 2, 843:853) ]
head(dat_all_train[1,841:850])
set.seed(1200)
dat_all_train <- dat_all_train[sample(nrow(dat_all_train)),]
glimpse(dat_all_train)
library(mlr)
labels = colnames(dat_all_train)[841:845]
(labels)
head(dat_all_train[1,841:850])
head(dat_all_train[1,840:850])
labels = colnames(dat_all_train)[843:850]
(labels)
labels = colnames(dat_all_train)[843:5081]
(labels)
multilabel.task = makeMultilabelTask(id = "multi", data = dat_all_train, target = labels)
?mtabulate
tags_ohe %>% mutate_if(is.numeric,as.factor)
tags_ohe %>% mutate_if(is.numeric,as.factor)
dat_all_new<-cbind(dat_all_new,tags_ohe)
dat_all_test<-tail(dat_all_new,15000)
dat_all_train<-dat_all_new[1:(nrow(dat_all_new)-15000),]
head(dat_all_train[1,840:850])
head(dat_all_train[1,844:850])
head(dat_all_train[1,844:850])
head(dat_all_train[1,840:850])
dat_all_train <- dat_all_train[ -c(1, 2,843 ) ]
head(dat_all_train[1,840:850])
head(dat_all_train[1,841:850])
set.seed(1200)
dat_all_train <- dat_all_train[sample(nrow(dat_all_train)),]
library(mlr)
dim(dat_all_train)
labels = colnames(dat_all_train)[841:845]
multilabel.task = makeMultilabelTask(id = "multi", data = dat_all_train, target = labels)
glimpse(dat_all_train)
head(tags_ohe)
library(data.table)
library(ggplot2)
library(tm)
library(SnowballC)
library(data.table)
library(ggplot2)
library(tm)
library(SnowballC)
# read in data
dat_bio <- read.csv('biology.csv', stringsAsFactors = F)
dat_cook <- read.csv('cooking.csv', stringsAsFactors = F)
dat_crypt <- read.csv('crypto.csv', stringsAsFactors = F)
dat_diy <- read.csv('diy.csv', stringsAsFactors = F)
dat_robot <- read.csv('robotics.csv', stringsAsFactors = F)
dat_travel <- read.csv('travel.csv', stringsAsFactors = F)
# attach a category label
dat_bio$category <- 'biology'
dat_cook$category <- 'cooking'
dat_crypt$category <- 'crypto'
dat_diy$category <- 'diy'
dat_robot$category <- 'robotics'
dat_travel$category <- 'travel'
# combine and remove from environment
dat_all <- rbind(dat_bio, dat_cook, dat_crypt, dat_diy, dat_robot, dat_travel)
rm(dat_bio, dat_cook, dat_crypt, dat_diy, dat_robot, dat_travel)
# duplicate id values across categories, concat id to category and we're good
print(sum(duplicated(dat_all$id)))  # 27,441
library(dplyr)
unique(dat_all$category)
# removes all html tags
remove_html_tags <- function(htmlString) {
return(gsub("<.*?>", "", htmlString))
}
title_content_pre=remove_html_tags(dat_all$title_content)
title_content_corpus = Corpus(VectorSource(title_content_pre))
title_content_corpus <- tm_map(title_content_corpus, content_transformer(tolower))
title_content_corpus <- tm_map(title_content_corpus, removeNumbers)
title_content_corpus <- tm_map(title_content_corpus, removePunctuation)
title_content_corpus <- tm_map(title_content_corpus, removeWords, c("the", "and", stopwords("english")))
title_content_corpus <-  tm_map(title_content_corpus, stripWhitespace)
title_content_corpus<- tm_map(title_content_corpus, stemDocument, "english")
#Merging title and content and creating a corpus
dat_all$title_content =  paste(dat_all$title, dat_all$content, sep=" ")
# removes all html tags
remove_html_tags <- function(htmlString) {
return(gsub("<.*?>", "", htmlString))
}
title_content_pre=remove_html_tags(dat_all$title_content)
title_content_corpus = Corpus(VectorSource(title_content_pre))
title_content_corpus <- tm_map(title_content_corpus, content_transformer(tolower))
title_content_corpus <- tm_map(title_content_corpus, removeNumbers)
title_content_corpus <- tm_map(title_content_corpus, removePunctuation)
title_content_corpus <- tm_map(title_content_corpus, removeWords, c("the", "and", stopwords("english")))
title_content_corpus <-  tm_map(title_content_corpus, stripWhitespace)
title_content_corpus<- tm_map(title_content_corpus, stemDocument, "english")
title_content_dtm_tfidf <- DocumentTermMatrix(title_content_corpus, control = list(weighting = weightTfIdf))
title_content_dtm_tfidf = removeSparseTerms(title_content_dtm_tfidf, 0.9999)
title_content_dtm_tfidf
title_content_dtm_tfidf <- DocumentTermMatrix(title_content_corpus, control = list(weighting = weightTfIdf))
title_content_dtm_tfidf = removeSparseTerms(title_content_dtm_tfidf, 0.99)
title_content_dtm_tfidf
dat_all_new = cbind(dat_all$tags, dat_all$category, as.matrix(title_content_dtm_tfidf))
library(data.table)
library(ggplot2)
library(tm)
library(SnowballC)
# read in data
dat_bio <- read.csv('biology.csv', stringsAsFactors = F)
dat_cook <- read.csv('cooking.csv', stringsAsFactors = F)
dat_crypt <- read.csv('crypto.csv', stringsAsFactors = F)
dat_diy <- read.csv('diy.csv', stringsAsFactors = F)
dat_robot <- read.csv('robotics.csv', stringsAsFactors = F)
dat_travel <- read.csv('travel.csv', stringsAsFactors = F)
# attach a category label
dat_bio$category <- 'biology'
dat_cook$category <- 'cooking'
dat_crypt$category <- 'crypto'
dat_diy$category <- 'diy'
dat_robot$category <- 'robotics'
dat_travel$category <- 'travel'
# combine and remove from environment
dat_all <- rbind(dat_bio, dat_cook, dat_crypt, dat_diy, dat_robot, dat_travel)
rm(dat_bio, dat_cook, dat_crypt, dat_diy, dat_robot, dat_travel)
# duplicate id values across categories, concat id to category and we're good
print(sum(duplicated(dat_all$id)))  # 27,441
library(dplyr)
unique(dat_all$category)
#Merging title and content and creating a corpus
dat_all$title_content =  paste(dat_all$title, dat_all$content, sep=" ")
# removes all html tags
remove_html_tags <- function(htmlString) {
return(gsub("<.*?>", "", htmlString))
}
title_content_pre=remove_html_tags(dat_all$title_content)
title_content_corpus = Corpus(VectorSource(title_content_pre))
title_content_corpus <- tm_map(title_content_corpus, content_transformer(tolower))
title_content_corpus <- tm_map(title_content_corpus, removeNumbers)
title_content_corpus <- tm_map(title_content_corpus, removePunctuation)
title_content_corpus <- tm_map(title_content_corpus, removeWords, c("the", "and", stopwords("english")))
title_content_corpus <-  tm_map(title_content_corpus, stripWhitespace)
title_content_corpus<- tm_map(title_content_corpus, stemDocument, "english")
title_content_dtm_tfidf <- DocumentTermMatrix(title_content_corpus, control = list(weighting = weightTfIdf))
title_content_dtm_tfidf = removeSparseTerms(title_content_dtm_tfidf, 0.999)
title_content_dtm_tfidf
title_content_dtm_tfidf <- DocumentTermMatrix(title_content_corpus, control = list(weighting = weightTfIdf))
title_content_dtm_tfidf = removeSparseTerms(title_content_dtm_tfidf, 0.99)
title_content_dtm_tfidf
dat_all_new = cbind(as.matrix(title_content_dtm_tfidf))
dat_all_new = data.frame(dat_all_new)
dat_all_train<-dat_all_new[1:(nrow(dat_all_new)-15000),]
dat_all_test<-tail(dat_all_new,15000)
#head(dat_all_new)
#dat_all_new  %>% mutate_if(is.factor,as.numeric)
tag_corpus = Corpus(VectorSource(dat_all$tags))
tag_corpus = tm_map(tag_corpus, content_transformer(tolower))
tag_corpus = tm_map(tag_corpus, stripWhitespace)
tag_corpus = tm_map(tag_corpus, removeNumbers)
tag_corpus = tm_map(tag_corpus, removePunctuation,preserve_intra_word_dashes=T)
library(qdapTools)
tags_train<-tag_corpus$content[1:(nrow(dat_all_new)-15000)]
tags_test<-tail(tag_corpus$content,15000)
tags_train_ohef<-cbind(tags_train, mtabulate(strsplit(tags_train, " ")))
tags_train_ohef<-cbind(tags_train, mtabulate(strsplit(tags_train, " ")))
tags_test_ohef<-cbind(tags_test, mtabulate(strsplit(tags_test, " ")))
xy_test<-cbind(category=dat_all$category[1:(nrow(dat_all_new)-15000)],tags_train_ohef)
head(xy_test)
xy_test %.% group_by(category) %.%
summarise(Sum=sum(Sum),
Sum_Squares = sum(Sum_Squares),
Count= sum(Count),
Average= sum(Average))
xy_test %.% group_by(category) %.%
summarise(Sum=sum(abe))
DT <- data.table(xy_test)
head(xy_test)
xy_test$tags_train<-NULL
head(xy_test)
DT <- data.table(xy_test)
xy<-DT[, lapply(.SD,sum), by=colnames(DT)[1]]
xy<-DT[, lapply(.SD,sum), by=list(category)]
head(xy)
colSums(xy != 0)
which(colSums(xy != 0)>1)
length(which(colSums(xy != 0)>1))
which(colSums(xy != 0)>1)
which(colSums(xy != 0)>1)
?makeLearner
??makeLearner
which(colSums(xy != 0)>2)
which(colSums(xy != 0)>1)
knitr::opts_chunk$set(echo = TRUE)
# Step 1 -> Read data into R workstation
#### Read data from a CSV file
#### Example: Alzheimer's Disease
# filename
# RCurl is the R package to read csv file using a link
library(RCurl)
AD <- read.csv(text=getURL("https://raw.githubusercontent.com/shuailab/ind_498/master/resource/data/AD_hd.csv"))
# str(AD)
X <- matrix(c(-20,-10,0,10,20,-8,-1,0,1,8), nrow = 5)
X_scale <- scale(X)
model.pca  <- eigen(cov(X_scale))
cov(X_scale)
model.pca
X.pca <- data.frame(X_scale %*% model.pca $vectors)
X.pca
?dim
Temperature<-c(200,250,200,200,189.65,260.35,225,225,225,225,225,225)
Concentration<-c(15,15,25,25,20,20,12.93,27.07,20,20,20,20)
Catalyst<-c(10,20,20,10,5,5,10,10,20,20,5,10)
Yield<-c(43,78,69,73,48,76,65,74,76,79,83,81)
